{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cab47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb7467dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "to_numpy = lambda x: x.numpy()\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e996ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d410385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer(layer, mean=0, std=1):\n",
    "    # Тут надо быть аккуратным — можно случайно создать копию и менять значения у копии\n",
    "    weight = layer.state_dict()['weight']\n",
    "    bias = layer.state_dict()['bias']\n",
    "    bias.zero_()\n",
    "    weight.normal_(mean=0, std=std)\n",
    "\n",
    "def forward_hook(self, input_, output):\n",
    "    std = input_[0].std().item()\n",
    "    print('forward', std)\n",
    "\n",
    "def backward_hook(self, grad_input, grad_output):\n",
    "    std = grad_input[0].std().item()\n",
    "    print('backward', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "080fc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = nn.Linear(28*28, 500)\n",
    "layer_2 = nn.Linear(500, 10)\n",
    "\n",
    "layer_1.register_forward_hook(forward_hook)\n",
    "layer_2.register_forward_hook(forward_hook)\n",
    "\n",
    "layer_1.register_backward_hook(backward_hook)\n",
    "layer_2.register_backward_hook(backward_hook)\n",
    "\n",
    "std_Xav1 = (6 / (28*28 + 500)) ** 0.5\n",
    "std_Xav2 = (6 / (500 + 10)) ** 0.5\n",
    "init_layer(layer_1, -std_Xav1, std_Xav1)\n",
    "init_layer(layer_2, std_Xav2, std_Xav2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6932651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward 0.9981620907783508\n",
      "forward 0.7789945006370544\n",
      "backward 0.027487371116876602\n",
      "backward 0.015442772768437862\n"
     ]
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    layer_1,\n",
    "    nn.Tanh(),\n",
    "    layer_2\n",
    ")\n",
    "\n",
    "n_objects = 100\n",
    "X = images_train[:n_objects].view(n_objects, -1).data\n",
    "y = labels_train[:n_objects].data\n",
    "activations = network(X)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "loss = loss_fn(activations, y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b129ce",
   "metadata": {},
   "source": [
    "При инициализации весов методом **He** в семинаре получились следующие значения:\n",
    "forward 0.9945185780525208\n",
    "forward 0.12716735899448395\n",
    "backward 0.019999997690320015\n",
    "backward 0.038504574447870255\n",
    "В итоге Xavier справился лучше с форвардом чем He, но backward изменения практически неощутимы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80c99d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.empty(X.shape).uniform_(0, 1).type(torch.FloatTensor)\n",
    "        if self.training:\n",
    "            mask = torch.where(mask > self.p, 1, 0)\n",
    "        else:\n",
    "            mask = torch.where(mask > self.p, 1, 1 - self.p)\n",
    "\n",
    "        return x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98a4f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropConnect(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DropConnect, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            mask = torch.empty_like(self.linear.weight).bernoulli_(1 - self.p).type(torch.FloatTensor)\n",
    "            mask = mask / (1 - self.p)\n",
    "        else:\n",
    "            mask = torch.ones_like(self.linear.weight) * (1 - self.p)\n",
    "        mask = mask.requires_grad_(False)\n",
    "        mask = mask.data\n",
    "        output = F.linear(x, self.linear.weight * mask, self.linear.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3cfc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNetwork(nn.Module):\n",
    "    def __init__(self, final_part):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = 1\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(channels, 2, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 4, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        #input_size = 7 * 7 * 4 = 196\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.final_part = final_part\n",
    "\n",
    "        self.log_softmax = nn.LogSoftmax(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_part(x)\n",
    "        return self.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa604c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    nn.Linear(196, 150),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(150, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(50, 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e519a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TestNetwork(nn.Sequential(*layers))\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea72f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.305858\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.894961\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.586218\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.302601\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.384069\n",
      "Test Epoch: 0\tLoss: 0.194472\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.279490\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.373657\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.275959\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.306757\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.364631\n",
      "Test Epoch: 1\tLoss: 0.138301\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.293401\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.208800\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.139512\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.118575\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.215893\n",
      "Test Epoch: 2\tLoss: 0.113630\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.081579\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.156122\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.177839\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.182638\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.277213\n",
      "Test Epoch: 3\tLoss: 0.092673\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.203929\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.143697\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.170493\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.146671\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.137750\n",
      "Test Epoch: 4\tLoss: 0.082874\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.157534\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.164320\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.180355\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.220992\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.118682\n",
      "Test Epoch: 5\tLoss: 0.081308\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.154723\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.088017\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.087089\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.149025\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.086287\n",
      "Test Epoch: 6\tLoss: 0.073745\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.123323\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.222783\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.150967\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.076609\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.054987\n",
      "Test Epoch: 7\tLoss: 0.068518\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.084366\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.089405\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.094969\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.080033\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.069421\n",
      "Test Epoch: 8\tLoss: 0.062161\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.109655\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.163919\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.082277\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.164404\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.090965\n",
      "Test Epoch: 9\tLoss: 0.066232\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    network.train()\n",
    "    for batch_idx, (images_train, labels_train) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        X = images_train.data\n",
    "        y = labels_train.data\n",
    "        output = network(X)\n",
    "        loss = loss_fn(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(X), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "    network.eval()\n",
    "    losses = []\n",
    "    for batch_idx, (images_test, labels_test) in enumerate(test_loader):\n",
    "        X = images_test.data\n",
    "        y = labels_test.data\n",
    "        output = network(X)\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print('Test Epoch: {}\\tLoss: {:.6f}'.format(\n",
    "            epoch, np.mean(losses)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c19e9e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DropConnect.__init__() missing 2 required positional arguments: 'input_dim' and 'output_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m layers = [\n\u001b[32m      2\u001b[39m     nn.Linear(\u001b[32m196\u001b[39m, \u001b[32m150\u001b[39m),\n\u001b[32m      3\u001b[39m     nn.ReLU(),\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mDropConnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m      5\u001b[39m     nn.Linear(\u001b[32m150\u001b[39m, \u001b[32m50\u001b[39m),\n\u001b[32m      6\u001b[39m     nn.ReLU(),\n\u001b[32m      7\u001b[39m     DropConnect(),\n\u001b[32m      8\u001b[39m     nn.Linear(\u001b[32m50\u001b[39m, \u001b[32m10\u001b[39m)\n\u001b[32m      9\u001b[39m ]\n\u001b[32m     11\u001b[39m network = TestNetwork(nn.Sequential(*layers))\n\u001b[32m     12\u001b[39m optimizer = torch.optim.Adam(network.parameters(), lr=\u001b[32m0.001\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: DropConnect.__init__() missing 2 required positional arguments: 'input_dim' and 'output_dim'"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    nn.Linear(196, 150),\n",
    "    nn.ReLU(),\n",
    "    DropConnect(),\n",
    "    nn.Linear(150, 50),\n",
    "    nn.ReLU(),\n",
    "    DropConnect(),\n",
    "    nn.Linear(50, 10)\n",
    "]\n",
    "\n",
    "network = TestNetwork(nn.Sequential(*layers))\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b552d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
